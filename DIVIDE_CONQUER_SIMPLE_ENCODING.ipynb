{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7aa557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 17:40:21.188195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 17:40:21.474773: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25e1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 256\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2f9528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file : republic\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for file in os.listdir(\"./data\"):\n",
    "    print(f\"Working on file : {file}\")\n",
    "    with open(f\"./data/{file}\", \"r\") as f:\n",
    "        data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ccfbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate\n",
    "data = \"\\n\".join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542d5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = re.sub(\"\\n+\", \"\\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75860fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went down yesterday to the Piraeus with Glaucon the son of Ariston, that I might offer up my prayers to the goddess (Bendis, the Thracian Artemis.); and also because I wanted to see in what manner they would celebrate the festival, which was a new thing. I was delighted with the procession of the inhabitants; but that of the Thracians was equally, if not more, beautiful. When we had finished our prayers and viewed the spectacle, we turned in the direction of the city; and at that instant Polem'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592a32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_char = sorted(list(set(data)))\n",
    "vocab_size = len(unique_char)\n",
    "\n",
    "str_to_int = {ch:i for i, ch in enumerate(unique_char)}\n",
    "int_to_str = {i:ch for i, ch in enumerate(unique_char)}\n",
    "encode = lambda s: [str_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_str[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f714ed34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size == len(str_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a505ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize for loading in the training notebook\n",
    "import pickle\n",
    "with open(\"str_to_int\", \"wb\") as f:\n",
    "    pickle.dump(str_to_int, f)\n",
    "\n",
    "with open(\"int_to_str\", \"wb\") as f:\n",
    "    pickle.dump(int_to_str, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c42479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 1, 72, 54, 63, 69, 1, 53, 64, 72, 63, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(data)[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5e5b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 17:40:37.683794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:37.856436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:37.856744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:37.860592: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 17:40:37.864470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:37.864643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:37.864753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:39.014720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:39.014825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:39.014879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 17:40:39.014944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14207 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "data = tf.convert_to_tensor(encode(data), tf.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781d7a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([637087])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6372b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.stack([data[idx:idx+block_size] for idx in range(len(data)-block_size)])\n",
    "y = tf.stack([data[idx+1:idx+block_size+1] for idx in range(len(data)-block_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea36fa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([636831, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5c0e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((x, y))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c16131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636831"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec853e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(dataset, train_split, val_split, test_split):\n",
    "    dataset_size = len(dataset)\n",
    "    dataset = dataset.shuffle(dataset_size)\n",
    "    train_size = int(train_split * dataset_size)\n",
    "    val_size = int(val_split * dataset_size)\n",
    "    \n",
    "    train_data = dataset.take(train_size)\n",
    "    val_data = dataset.skip(train_size).take(val_size)\n",
    "    test_data = dataset.skip(train_size+val_size)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb68fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = train_val_test_split(data, 0.7, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87a0199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111445"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the train:\n",
    "# We split it into 4 shards\n",
    "offset = len(train) // 4\n",
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1082a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_list = []\n",
    "for i in range(4):\n",
    "    if i == 3:\n",
    "        shard_list.append(train.skip(offset * i).shuffle(offset).batch(batch_size))\n",
    "    else:\n",
    "        shard_list.append(train.skip(offset * i).take(offset).shuffle(offset).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3924bd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shard_list[0]) == len(shard_list[1]) == len(shard_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82a81bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shard_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba6ae545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>,\n",
       " <BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>,\n",
       " <BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>,\n",
       " <BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15dc8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, ds in enumerate(shard_list):\n",
    "    ds.save(f\"./shards/shard_simple_{ind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ebe174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val.batch(batch_size)\n",
    "val.save(\"./shards/val_shard_simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "085a5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.batch(batch_size)\n",
    "test.save(\"./shards/test_shard_simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d423ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./shards\"\n",
    "shards = []\n",
    "for file in os.listdir(path):\n",
    "    if file.startswith(\"shard_simple\"):\n",
    "        shards.append(tf.data.Dataset.load(f\"{path}/{file}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e92f4ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_LoadDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>,\n",
       " <_LoadDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>,\n",
       " <_LoadDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>,\n",
       " <_LoadDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.float16, name=None), TensorSpec(shape=(None, 256), dtype=tf.float16, name=None))>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0035ef8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 256), dtype=float16, numpy=\n",
       " array([[67., 60., 50., ...,  1., 61., 70.],\n",
       "        [69.,  1., 69., ..., 63.,  1., 69.],\n",
       "        [69., 57., 54., ..., 64., 67., 53.],\n",
       "        ...,\n",
       "        [58., 52., 57., ...,  1., 57., 54.],\n",
       "        [62.,  1., 69., ...,  1., 68., 50.],\n",
       "        [57., 58., 63., ..., 68., 23.,  1.]], dtype=float16)>,\n",
       " <tf.Tensor: shape=(64, 256), dtype=float16, numpy=\n",
       " array([[60., 50., 51., ..., 61., 70., 53.],\n",
       "        [ 1., 69., 74., ...,  1., 69., 57.],\n",
       "        [57., 54.,  1., ..., 67., 53., 68.],\n",
       "        ...,\n",
       "        [52., 57.,  1., ..., 57., 54.,  1.],\n",
       "        [ 1., 69., 57., ..., 68., 50., 58.],\n",
       "        [58., 63., 60., ..., 23.,  1., 46.]], dtype=float16)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(shards[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3058930e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a71da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
